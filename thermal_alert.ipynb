{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal Alert \n",
    "\n",
    "\n",
    "### The Gist \n",
    "\n",
    "A PostgreSQL database is standing on smalls (Jay's machine)\n",
    "\n",
    "- **host**: smalls \n",
    "- **port**: 9001 \n",
    "- **owner**: kelvin \n",
    "- **password**: 1234\n",
    "- **database**: thermal\n",
    "\n",
    "PGAdmin is running @ `smalls:9002`\n",
    "\n",
    "Each dataset has it's own schema, currently the only one is LANDSAT_8_C1. \n",
    "\n",
    "<html>\n",
    "  <head>\n",
    "    <title></title>\n",
    "    <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
    "    <style type=\"text/css\">\n",
    "      body { font-family: verdana, arial, helvetica, sans-serif; font-size: smaller; }\n",
    "      table { padding: 0px;  margin: 0px; border: 1px solid #dddddd; border-collapse: collapse; }\n",
    "      tr { font-size: smaller; }\n",
    "      th, td { border: 1px solid #dddddd; padding: 2px; }\n",
    "      /*table.info { background: #ffffff; }*/\n",
    "      /*table.data { background: #ffffff; }*/\n",
    "      /*tr.even { background: #ffffff; }*/\n",
    "      /*tr.odd { background: #eeeeee; }*/\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "    <br>\n",
    "    <table class=\"data\">\n",
    "      <tr>\n",
    "        <th>table_schem</th>\n",
    "        <th>table_name</th>\n",
    "        <th>table_type</th>\n",
    "        <th>remarks</th>\n",
    "      </tr>\n",
    "      <tr class=\"even\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"image_attributes\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"Contains misc attributes such as cloud cover, sun azimuth and saturated band info. \"</td>\n",
    "      </tr>\n",
    "      <tr class=\"odd\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"images\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"Contains file path to band geotiffs and metadata files along with a spatiotemporal index.  \"</td>\n",
    "      </tr>\n",
    "      <tr class=\"even\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"metadata_file_info\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"Landsat 8 c1 specific file id&#39;s and bookkeeping info \"</td>\n",
    "      </tr>\n",
    "      <tr class=\"odd\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"min_max_pixel_value\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>N/A</td>\n",
    "      </tr>\n",
    "      <tr class=\"even\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"min_max_radiance\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>N/A</td>\n",
    "      </tr>\n",
    "      <tr class=\"odd\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"min_max_reflectance\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>N/A</td>\n",
    "      </tr>\n",
    "      <tr class=\"even\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"product_metadata\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"Spatial info include lat lon extents, row&#47;path, and  file names. \"</td>\n",
    "      </tr>\n",
    "      <tr class=\"odd\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"projection_parameters\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>N/A</td>\n",
    "      </tr>\n",
    "      <tr class=\"even\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"radiometric_rescaling\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"Columns containing constants for converting to and from reflectance and radiance.\"</td>\n",
    "      </tr>\n",
    "      <tr class=\"odd\">\n",
    "        <td>\"landsat_8_c1\"</td>\n",
    "        <td>\"tirs_thermal_constants\"</td>\n",
    "        <td>\"TABLE\"</td>\n",
    "        <td>\"K1 and K2 constants for converting to and from brightness temp.\"</td>\n",
    "      </tr>\n",
    "    </table>\n",
    "  </body>\n",
    "</html>\n",
    "\n",
    "All the functions written below make the addumption that the in-memory dataframes maintain the same format as the tables above (hit up `smalls:9002` and look through PGAdmin if you want to get specific column info).  \n",
    "\n",
    "### Notes\n",
    "* It seems like USGS EROS doesn't tag their day/night images correctly and some daytime images being downloaded despite specifically querying for night time. After speaking with Greg, seems I can filter based on row/path instead of relying on USGS tagging. \n",
    "* The algorithm given to me by Greg for brightness temp didn't seem correct. I got values in the ~-500 K range. Using the algorithm given by USGS EROS (https://landsat.usgs.gov/using-usgs-landsat-8-product) seems to give brightness temps arround ~300 K which I believe is more expected? Need someone to check my math here. \n",
    "* VAST was written by Cole, but I haven't gotten my hands on the function yet, it's finals week so it's reasonable. \n",
    "* RST isnt't here either, I need re-poplulate the DB with correct night/day tagging else the output is all wrong. \n",
    "* A lot of this is temporary, since the underlying data structures are likely to change. The question of a good data structure is a bit of a challenge at the moment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krodriguez/anaconda3/envs/numel/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import bayleef\n",
    "import geopandas as gpd\n",
    "\n",
    "import plio\n",
    "from plio.io.io_gdal import GeoDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pylab import rcParams\n",
    "import numpy as np\n",
    "import gdal \n",
    "from os import path\n",
    "import os\n",
    "import math\n",
    "import osr \n",
    "import hashlib\n",
    "import pvl\n",
    "from glob import glob \n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from geoalchemy2.shape import from_shape\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from sqlalchemy import *\n",
    "import re\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "landsat8_wavelengths = [None, 0.435, \n",
    "                        0.452, 0.533, \n",
    "                        0.636, 0.851,\n",
    "                        1.566, 2.107,\n",
    "                        0.503, 1.363,\n",
    "                        11.19, 12.51]\n",
    "\n",
    "def modvolc(mir, tir, thresh=-.8, nodata=0):\n",
    "    \"\"\"\n",
    "    Modvolc computation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mir : np.array \n",
    "          array containing mid infrared DNs for computing nti\n",
    "    tir : np.array \n",
    "          array containing thermal infrared DNs for computing nti\n",
    "    thresh : float\n",
    "             Pixels where nti >= tresh are tagged as anomolies \n",
    "    nodata : float \n",
    "             DNs in mir and tir equal to the no data values are replaced \n",
    "             with np.nan\n",
    "             \n",
    "    Returns\n",
    "    -------\n",
    "    : np.array \n",
    "      Boolean array of pixels flagged as anomolies \n",
    "    : np.array\n",
    "      Computed nti array where nti = (mir - tir)/(mir + tir)\n",
    "    \n",
    "    \"\"\"\n",
    "    tir[tir == nodata] = np.nan\n",
    "    mir[mir == nodata] = np.nan\n",
    "    nti = (mir - tir)/(mir + tir)\n",
    "    \n",
    "    anomolies = np.empty(nti.shape)\n",
    "    anomolies[:] = False\n",
    "    anomolies[np.isnan(nti)] = np.nan\n",
    "    anomolies[nti >= thresh] = True\n",
    "    return anomolies, nti\n",
    "\n",
    "\n",
    "def modvolc_df(df, mir_band, tir_band, thresh=-.8):\n",
    "    \"\"\"\n",
    "    Runs the modvolc algorithm on a pandas dataframe, assumes format matches the \n",
    "    postgres database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : DataFrame\n",
    "         Pandas DataFrame to apply modvolc to\n",
    "    mir : str\n",
    "          Mid infrared column, this is the column that contains the image\n",
    "          used as the mir band, usually b6 or b7\n",
    "    tir : str\n",
    "          Thermal infrared column,this is the column that contains the image\n",
    "          used as the tir band, usually b10 or b11\n",
    "    thresh : float \n",
    "             Threshhold to be passed to modvolc, where anomolies == where(nti >= thresh)\n",
    "    \n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    \n",
    "    : DataFrame\n",
    "      Dataframe with new columns \"modvolc_anomolies\" and \"nti\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def modvolc_row(row, mir_band, tir_band):\n",
    "        mir_arr = row[mir_band].read_array()\n",
    "        tir_arr = row[tir_band].read_array()\n",
    "        \n",
    "        anomolies, nti = modvolc(mir_arr, tir_arr, thresh)\n",
    "        anomolies = array2raster(row[tir_band], anomolies, os.path.join('/vsimem',hash_dataset(anomolies)))\n",
    "        nti = array2raster(row[tir_band], nti, os.path.join('/vsimem', hash_dataset(nti)))\n",
    "        row['modvolc_anomolies'], row['nti'] = anomolies, nti\n",
    "        return row\n",
    "    return df.apply(modvolc_row, axis=1, mir_band=mir_band, tir_band=tir_band)\n",
    "    \n",
    "\n",
    "def hash_dataset(arr=None):\n",
    "    \"\"\"\n",
    "    Hashes an array. Values are rounded to one decimal place so to avoid \n",
    "    issues of floating point inaccuracies. Useful for programtically generating \n",
    "    filenames for GDAL files. As GDAL file are kept in memory using GDAL's virtual file system \n",
    "    until explicitly written to disk, a hashing function is used to \n",
    "    generate it's name in the virtual file system. This way similar array data is simply \n",
    "    overwritten in the file system.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.array \n",
    "          Numpy array to be hashed.\n",
    "          \n",
    "    Returns \n",
    "    -------\n",
    "    : str \n",
    "      Generated hash string \n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(arr, GeoDataset):\n",
    "        arr = arr.read_array()\n",
    "    \n",
    "    string = \"shape={}\".format(arr.shape)\n",
    "    string += str(np.round(arr,1))\n",
    "    string += str(round(np.min(arr), 1))\n",
    "    string += str(round(np.max(arr), 1))\n",
    "    string += str(round(np.sum(arr), 1))\n",
    "    \n",
    "    sha1 = hashlib.sha1(string.replace(' ', '').replace('\\n','').encode()).hexdigest()\n",
    "    return sha1\n",
    "\n",
    "\n",
    "def crop(cropfile, extents, use_latlon=True):\n",
    "    \"\"\"\n",
    "    Uses the virtual file system (http://www.gdal.org/gdal_virtual_file_systems.html)\n",
    "    to crop an image in memory. TODO: Make this less jank, super slow\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    cropfile : str\n",
    "               Path to file to crop\n",
    "    extents : list\n",
    "              list in the format: [ul y, ul x, lr y, lr x]\n",
    "    use_latlon : bool\n",
    "                 if True, extents are in lat lon ranges for bounding box, \n",
    "                 else they are in pixel ranges.\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    : GeoDataset \n",
    "      The cropped file\n",
    "    \n",
    "    \"\"\"\n",
    "    # hash the image info to get the filename\n",
    "    filename = hash_dataset(cropfile)\n",
    "    \n",
    "    if use_latlon:\n",
    "        ul = np.asarray(cropfile.latlon_to_pixel(extents[0], extents[1]))\n",
    "        lr = np.asarray(cropfile.latlon_to_pixel(extents[2], extents[3]))\n",
    "        window_size = np.abs(ul-lr)\n",
    "        extents = [ul[0], ul[1], window_size[0], window_size[1]]\n",
    "    \n",
    "    clip = gdal.Translate(path.join('/vsimem', filename), cropfile.file_name, srcWin=extents)\n",
    "    return GeoDataset(clip.GetDescription())\n",
    "\n",
    "\n",
    "def pixels_to_latlon(geodataset, locs):\n",
    "    \"\"\"\n",
    "    Converts a list of pixels into lat lon space given a reference \n",
    "    image. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    geodataset : GeoDataset \n",
    "                 Reference image with tranformation info for conversion\n",
    "    locs : list \n",
    "           list of x,y pixel pairs to convert\n",
    "           \n",
    "    Returns \n",
    "    -------\n",
    "    : list \n",
    "      List of lat lon pairs\n",
    "    \"\"\"\n",
    "    coords = []\n",
    "    for loc in locs:\n",
    "        coords.append(geodataset.pixel_to_latlon(loc[1], loc[0]))\n",
    "    return coords\n",
    "\n",
    "\n",
    "def to_geodataset(dataset):\n",
    "    \"\"\"\n",
    "    Simple function to convert between GDAL dataset and Plio \n",
    "    GeoDataset. TODO: The fact that this function exists tells me it \n",
    "    might be usful to consolidate the two data structures to \n",
    "    have similar interfaces. \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    dataset : Dataset \n",
    "              GDAL Dataset to convert\n",
    "              \n",
    "    Returns \n",
    "    -------\n",
    "    : Geodataset\n",
    "      The converted GeoDataset\n",
    "    \"\"\"\n",
    "    if not isinstance(dataset, GeoDataset):\n",
    "        return GeoDataset(path.abspath(dataset.GetDescription()))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def array2raster(rasterfn, array, newRasterfn):\n",
    "    \"\"\"\n",
    "    Writes an array to a GeoDataset using another dataset as reference. Borrowed  \n",
    "    from: https://pcjericks.github.io/py-gdalogr-cookbook/raster_layers.html\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    rasterfn : str, GeoDataset\n",
    "               Dataset or path to the dataset to use as a reference. Geotransform \n",
    "               and spatial reference information is copied into the new image. \n",
    "               \n",
    "    array : np.array \n",
    "            Array to write \n",
    "            \n",
    "    newRasterfn : str \n",
    "                  Filename for new raster image \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    : GeoDataset \n",
    "      File handle for the new raster file\n",
    "      \n",
    "    \"\"\"\n",
    "    naxis = len(array.shape)\n",
    "    assert naxis == 2 or naxis == 3      \n",
    "    \n",
    "    if naxis == 2:\n",
    "        # exapnd the third dimension\n",
    "        array = array[:,:,None]\n",
    "    \n",
    "    nbands = array.shape[2]\n",
    "    \n",
    "    if isinstance(rasterfn, GeoDataset):\n",
    "        rasterfn = rasterfn.file_name\n",
    "    \n",
    "    raster = gdal.Open(rasterfn)\n",
    "    geotransform = raster.GetGeoTransform()\n",
    "    originX = geotransform[0]\n",
    "    originY = geotransform[3]\n",
    "    pixelWidth = geotransform[1]\n",
    "    pixelHeight = geotransform[5]\n",
    "    cols = raster.RasterXSize\n",
    "    rows = raster.RasterYSize\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, nbands, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    \n",
    "    for band in range(1,nbands+1):\n",
    "        outband = outRaster.GetRasterBand(band)\n",
    "        # Bands use indexing starting at 1\n",
    "        outband.WriteArray(array[:,:,band-1])\n",
    "        outband.FlushCache()\n",
    "    \n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromWkt(raster.GetProjectionRef())\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outRaster = None\n",
    "    return GeoDataset(newRasterfn)\n",
    "\n",
    "\n",
    "def get_band_columns(df):\n",
    "    \"\"\"\n",
    "    Returns a list of available bands given a dataframe \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : DataFrame \n",
    "         input dataframe \n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    : list \n",
    "      List of avaailable bands\n",
    "    \"\"\"\n",
    "    band_pattern = re.compile(\"^b([0-9]+)\")\n",
    "    bands = [column for column in df.columns if band_pattern.match(column)]\n",
    "    return bands\n",
    "\n",
    "    \n",
    "def write_array(dataset, array, out=None):\n",
    "    \"\"\"\n",
    "    Like array2raster but jankier. Probably shouldn't be used, will delete later.\n",
    "    \"\"\"\n",
    "    naxis = len(array.shape)\n",
    "    assert naxis == 2 or naxis == 3      \n",
    "    \n",
    "    if naxis == 2:\n",
    "        # exapnd the third dimension\n",
    "        array = array[:,:,None]\n",
    "    \n",
    "    nbands = array.shape[2]\n",
    "    \n",
    "    if nbands > dataset.nbands:\n",
    "        for i in range(nbands-dataset.nbands):\n",
    "            dataset.dataset.AddBand()\n",
    "    \n",
    "    if out:\n",
    "        # copy the file \n",
    "        new_dataset = gdal.Translate(out, dataset.file_name)\n",
    "        for band in range(nbands):\n",
    "            outBand = new_dataset.GetRasterBand(band+1)\n",
    "            outBand.WriteArray(array[:,:,band])\n",
    "        del new_dataset\n",
    "        return GeoDataset(out)\n",
    "    \n",
    "    # Else use virtual filesystem\n",
    "    temp = gdal.Translate('/vsimem/temp', dataset.file_name)\n",
    "    for band in range(nbands):\n",
    "        outBand = temp.GetRasterBand(band+1)\n",
    "        outBand.WriteArray(array[:,:,band])\n",
    "\n",
    "    # copy file into proper name and delete temp\n",
    "    del temp\n",
    "    return to_geodataset(gdal.Translate(path.join('/vsimem/', hash_dataset('/vsimem/temp')), '/vsimem/temp'))\n",
    "\n",
    "\n",
    "def df2gdal(df, roi=None):\n",
    "    \"\"\"\n",
    "    Opens all the file paths in a dataframe to GeoDatasets. Input dataframe is expected \n",
    "    to have all columns mimicking that of the postgres schema for landsat8. Specifically, it will \n",
    "    only convert file names with columns b<#> where # is a band number 1-11. Should be upgraded soon \n",
    "    for other datasets. \n",
    "\n",
    "    This should be run before any computational function can be used on the Dataframe.\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : DataFrame \n",
    "         input dataframe \n",
    "    roi : list \n",
    "          Region on interest expressed as lat lon corners: [ul y, ul x, lr y, lr x]\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    : DataFrame \n",
    "      copy of the input dataframe with band columns replaced by GeoDataset objects\n",
    "    \"\"\"\n",
    "    def read_bands(row, roi=None):\n",
    "        band_pattern = re.compile(\"^b([0-9]+)\")\n",
    "        bands = [column for column in df.columns if band_pattern.match(column)]\n",
    "        for band in bands:\n",
    "            row[band] = GeoDataset(row[band])\n",
    "            if roi:\n",
    "                row[band] = crop(row[band], roi)\n",
    "        return row\n",
    "    \n",
    "    return df.apply(read_bands, axis=1, roi=roi)\n",
    "\n",
    "\n",
    "def animate_band(images, cmap='plasma'):\n",
    "    \"\"\"\n",
    "    Given a Series of images, draws an animation iterating over \n",
    "    images in the order they are presented in the Series. \n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    images : Series, list \n",
    "             Series or list of GeoDataset images\n",
    "    cmap : cmap, str\n",
    "           Matplotlib color map for coloring\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    : FuncAnimation\n",
    "      Matplotlib Animation\n",
    "    \n",
    "    \"\"\"\n",
    "    imagelist = list(images)\n",
    "    arrlist = []\n",
    "    for im in imagelist:\n",
    "        arr = im.read_array()\n",
    "        arr[arr == 0] = np.nan\n",
    "        arrlist.append(arr)\n",
    "\n",
    "    fig = plt.figure() # make figure\n",
    "\n",
    "    # make axesimage object\n",
    "    # the vmin and vmax here are very important to get the color map correct\n",
    "    im = plt.imshow(arrlist[0], cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    # function to update figure\n",
    "    def updatefig(j):\n",
    "        # set the data in the axesimage object\n",
    "        im.set_array(arrlist[j])\n",
    "        # return the artists set\n",
    "        return [im]\n",
    "    # kick off the animation\n",
    "    ani = animation.FuncAnimation(fig, updatefig, frames=len(arrlist), repeat_delay=900,\n",
    "                                  interval=400, repeat=True, blit=True)\n",
    "    return ani\n",
    "\n",
    "\n",
    "def df2radiance(df):\n",
    "    \"\"\"\n",
    "    Coverts the Geodatasets in the input dataframe to radiance. New columns \n",
    "    in the form b<#>_rad for each available band in the dataframe containing a \n",
    "    GeoDataset with radiance values.\n",
    "    \n",
    "    Only converts columns with the name b<#> where '#' is some band number. As\n",
    "    this currently only works with Landsat 8, # has to be 1-11. Also, the \n",
    "    multiplication and addition constants must be in the DataFrame using the \n",
    "    Standard name that is used in the meta file attached to the Landsat scene.\n",
    "    i.e. radiance_mult_band_<#> and radiance_add_band_<#>\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : DataFrame \n",
    "         input dataframe\n",
    "         \n",
    "    Returns \n",
    "    -------\n",
    "    : DataFrame \n",
    "      A copy of the input DataFrame with new columns for radiance rasters \n",
    "    \"\"\"\n",
    "    def row_radiance(row):\n",
    "        for bandnum in range(1,12):            \n",
    "            band_col = 'b{}'.format(bandnum)\n",
    "            if not band_col in row.index:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(row[band_col], str):\n",
    "                file = GeoDataset(row[band_col])\n",
    "            else:\n",
    "                file = row[band_col]\n",
    "            \n",
    "            arr = file.read_array()\n",
    "            mult = row['radiance_mult_band_{}'.format(bandnum)]\n",
    "            add = row['radiance_add_band_{}'.format(bandnum)]\n",
    "            rad_arr = (arr * float(mult)) + float(add)\n",
    "            \n",
    "            row[band_col+'_rad'] = array2raster(file, rad_arr, hash_dataset(rad_arr))\n",
    "        return row\n",
    "    return df.apply(row_radiance, axis=1)\n",
    "\n",
    "\n",
    "def df2brightness(df, e=1):\n",
    "    \"\"\"\n",
    "    Coverts the Geodatasets in the input dataframe to brightness temps. New columns \n",
    "    in the form b<#>_bright_temp for each available band in the dataframe containing a \n",
    "    GeoDataset with radiance values.\n",
    "    \n",
    "    Only converts columns with the name b<#> where '#' is some band number. As\n",
    "    this currently only works with Landsat 8, # has to be 10 and/or 11. Also, the \n",
    "    k1 and k2 constants must be in the DataFrame using the \n",
    "    Standard name that is used in the meta file attached to the Landsat scene.\n",
    "    i.e. radiance_mult_band_<#> and radiance_add_band_<#>\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    df : DataFrame \n",
    "         input dataframe\n",
    "         \n",
    "    Returns \n",
    "    -------\n",
    "    : DataFrame \n",
    "      A copy of the input DataFrame with new columns for brightness temp rasters \n",
    "    \"\"\"\n",
    "    def row_brightness(row, e):\n",
    "        C1 = 1.1910428e-16\n",
    "        C2 = 0.0143877513\n",
    "        for bandnum in range(10,12):\n",
    "            rad_col = 'b'+str(bandnum)+'_rad'\n",
    "            k1_const_col = 'k1_constant_band_{}'.format(bandnum) \n",
    "            k2_const_col = 'k2_constant_band_{}'.format(bandnum)\n",
    "            if not rad_col in row.index or not k1_const_col in row.index or not k2_const_col in row.index:\n",
    "                raise Exception('Input does not have the required columns')\n",
    "            \n",
    "            # convert micrometers to meteres\n",
    "            wvl = landsat8_wavelengths[bandnum] \n",
    "            rad_arr = row[rad_col].read_array()\n",
    "            k1_const = float(row[k1_const_col])\n",
    "            k2_const = float(row[k2_const_col])\n",
    "            \n",
    "            bright_arr = k2_const/np.log(((e*k1_const)/rad_arr)+1) \n",
    "            \n",
    "            row['b'+str(bandnum)+'_bright_temp'] = array2raster(row[rad_col], bright_arr, hash_dataset(bright_arr)) \n",
    "        return row\n",
    "    return df.apply(row_brightness, axis=1, e=e)\n",
    "\n",
    "\n",
    "def bright_temp_diff_df(df, thresh=1.5):\n",
    "    \"\"\"\n",
    "    Diffs the brightness temps for band 10 and 11. Any values in the diff array \n",
    "    with values above the given threshhold are flagged as anomolies. \n",
    "    \n",
    "    Input dataframe must have the columns b10_bright_temps and b11_bright_temps \n",
    "    computed before use. \n",
    "    \n",
    "    Output dataframe contains two new columns: bright_temp_diff and bright_temp_anomolies \n",
    "    for raster files containing the diff images and anomoly array respectively. \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "         input dataframe \n",
    "    thresh : float \n",
    "             thresh to use in anomoly tagging\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    : Dataframe\n",
    "      Copy of input dataframe \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if 'b10_bright_temp' not in df.columns or 'b11_bright_temp' not in df.columns:\n",
    "        raise Exception(\"Brightness values got b10 and b11 not in the dataframe\")\n",
    "    \n",
    "    def diff_row_brightness(row, thresh=1.5):\n",
    "        b10_bright_arr = row['b10_bright_temp'].read_array()\n",
    "        b11_bright_arr = row['b11_bright_temp'].read_array()\n",
    "        diff_arr = b10_bright_arr - b11_bright_arr\n",
    "        anomolies = np.empty(diff_arr.shape)\n",
    "        anomolies[:] = False\n",
    "        anomolies[np.isnan(diff_arr)] = np.nan\n",
    "        anomolies[diff_arr >= thresh] = True\n",
    "        row['bright_temp_diff'] = array2raster(row['b10_bright_temp'], diff_arr, hash_dataset(diff_arr))\n",
    "        row['bright_temp_anomolies'] = array2raster(row['b10_bright_temp'], anomolies, hash_dataset(anomolies))\n",
    "        return row\n",
    "    return df.apply(diff_row_brightness, axis=1, thresh=thresh)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['geom', 'time', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "        'b10', 'b11', 'bqa', 'metafile', 'ang', 'radiance_add_band_1',\n",
       "        'radiance_add_band_10', 'radiance_add_band_11', 'radiance_add_band_2',\n",
       "        'radiance_add_band_3', 'radiance_add_band_4', 'radiance_add_band_5',\n",
       "        'radiance_add_band_6', 'radiance_add_band_7', 'radiance_add_band_8',\n",
       "        'radiance_add_band_9', 'radiance_mult_band_1', 'radiance_mult_band_10',\n",
       "        'radiance_mult_band_11', 'radiance_mult_band_2', 'radiance_mult_band_3',\n",
       "        'radiance_mult_band_4', 'radiance_mult_band_5', 'radiance_mult_band_6',\n",
       "        'radiance_mult_band_7', 'radiance_mult_band_8', 'radiance_mult_band_9',\n",
       "        'reflectance_add_band_1', 'reflectance_add_band_2',\n",
       "        'reflectance_add_band_3', 'reflectance_add_band_4',\n",
       "        'reflectance_add_band_5', 'reflectance_add_band_6',\n",
       "        'reflectance_add_band_7', 'reflectance_add_band_8',\n",
       "        'reflectance_add_band_9', 'reflectance_mult_band_1',\n",
       "        'reflectance_mult_band_2', 'reflectance_mult_band_3',\n",
       "        'reflectance_mult_band_4', 'reflectance_mult_band_5',\n",
       "        'reflectance_mult_band_6', 'reflectance_mult_band_7',\n",
       "        'reflectance_mult_band_8', 'reflectance_mult_band_9',\n",
       "        'k1_constant_band_10', 'k1_constant_band_11', 'k2_constant_band_10',\n",
       "        'k2_constant_band_11'],\n",
       "       dtype='object'), (88, 60))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect directly for now until thin interface through Scott's restful service can me created\n",
    "engine = create_engine('postgresql://kelvin:1234@smalls:9001/thermal')\n",
    "\n",
    "# Load all the things into memory\n",
    "# Use pre-baked view on postgres\n",
    "sql = \"select * from landsat_8_c1 order by time\"\n",
    "df = gpd.GeoDataFrame.from_postgis(sql, engine , geom_col='geom').set_index('landsat_scene_id')\n",
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 55s, sys: 3min 15s, total: 9min 10s\n",
      "Wall time: 14min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# limit fields to fields we actually care about\n",
    "df = df[['geom', 'time', 'b6', 'b7', 'b10','b11', \n",
    "    'radiance_add_band_7', 'radiance_mult_band_7',\n",
    "    'radiance_add_band_6', 'radiance_mult_band_6',\n",
    "    'radiance_add_band_11', 'radiance_mult_band_11',\n",
    "    'radiance_add_band_10', 'radiance_mult_band_10',\n",
    "    'k1_constant_band_10', 'k1_constant_band_11',\n",
    "    'k2_constant_band_10', 'k2_constant_band_11']]\n",
    "\n",
    "# Cropping is expesive \n",
    "data = df2gdal(df, roi=[19.445, -155.321, 19.343,-155.164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2radiance(data)\n",
    "animate_band(data['b10_rad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df2brightness(data)\n",
    "animate_band(data['b11_bright_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = modvolc_df(data, 'b6_rad', 'b10_rad', thresh=-.75)\n",
    "data = bright_temp_diff_df(data, thresh=1.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "animate_band(data['bright_temp_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_band(data['modvolc_anomolies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data['bright_temp_anomolies'][0].read_array())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data['modvolc_anomolies'][0].read_array())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data['nti'][0].read_array())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
